{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Automated Flood Detection based on Satellite Images</h1>\n",
    "<br>\n",
    "This project focuses on flood detection using only the SEN2 data from the SEN12-FLOOD dataset. The goal is to process Sentinel-2 satellite images, specifically four spectral bands: Band2 (blue), Band3 (green), Band4 (red), and Band8 (infrared). These bands are important for distinguishing between land, water, and other surface features. The process involves organizing the data, checking for empty images, and stacking the bands together for further analysis, which will be used for flood detection tasks.\n",
    "<br>\n",
    "<hr>\n",
    "Dataset:<br>\n",
    "Clément Rambour, Nicolas Audebert, Elise Koeniguer, Bertrand Le Saux, Michel Crucianu, Mihai Datcu. (2020). SEN12-FLOOD : a SAR and Multispectral Dataset for Flood Detection . IEEE Dataport. https://dx.doi.org/10.21227/w6xz-s898\n",
    "\n",
    "Download (after free registration) - 12,2Gb: https://ieee-dataport.org/open-access/sen12-flood-sar-and-multispectral-dataset-flood-detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Directory Setup</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_empty_img(url):\n",
    "    \n",
    "    path = os.path.join(url, 'B02.tif')\n",
    "\n",
    "# Load the image in grayscale mode (0)\n",
    "    image = cv2.imread(path,0)\n",
    "  \n",
    " # Return True if all pixels are zero (empty image), otherwise False\n",
    "    if (cv2.countNonZero(image) == 0):\n",
    "        return  True\n",
    "    else:\n",
    "        return  False\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_folders(path):\n",
    "    # Delete the folder and all its contents\n",
    "    shutil.rmtree(path)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir_structure(flist):\n",
    "    for folder in flist:\n",
    "        prefix = folder[:11]    # Extract prefix from folder name\n",
    "        id = folder[11:]        # Extract id from folder name\n",
    "\n",
    "        if len(id) > 4: continue # Skip if id length is more than 4, because the id can be at most 4 digits\n",
    "\n",
    "        for file in os.listdir(folder):\n",
    "\n",
    "            if file.startswith('S1'): \n",
    "                os.remove(os.path.join(prefix + id, file)) # Remove files starting with 'S1'\n",
    "                continue\n",
    "            # If the file is a spectral band (B02, B03, B04, B08)\n",
    "            if file.endswith('B02.tif') or file.endswith('B03.tif') or file.endswith('B04.tif') or file.endswith('B08.tif'):\n",
    "                date = file[3:13] # Extract date from file name\n",
    "                newFolder =  os.path.join(prefix,'S2_' + id + '_'+ date) # Create new folder name\n",
    "\n",
    "                if os.path.isdir(newFolder):\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(newFolder, file[14:])) # Move file if folder exists\n",
    "                else:\n",
    "                    os.mkdir(newFolder)     # Create folder if it doesn't exist\n",
    "                    shutil.move(os.path.join(folder, file), os.path.join(newFolder, file[14:]))  # Move file\n",
    "\n",
    "        remove_folders(folder) # Remove the original folder after moving files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_bands(path):\n",
    "\n",
    "    band_list = ['B02.tif', 'B03.tif', 'B04.tif', 'B08.tif']\n",
    "    try:\n",
    "        \n",
    "        # Read metadata from the first band (B02.tif) \n",
    "        with rasterio.open(os.path.join(path, band_list[0])) as src0:\n",
    "            meta = src0.meta # Extract metadata from the first band\n",
    "        \n",
    "        # Update metadata to reflect the number of bands (layers) \n",
    "        meta.update(count = len(band_list))\n",
    "\n",
    "       # Create a new stack file and write each band to it\n",
    "        with rasterio.open(os.path.join(path, 'stack.tif'), 'w', **meta) as dst:\n",
    "            for id, layer in enumerate(band_list, start=1):\n",
    "                with rasterio.open(os.path.join(path, layer)) as src1:\n",
    "                    dst.write_band(id, src1.read(1)) # Write each band to the stack file\n",
    "    except:\n",
    "        print(\"Folder with no Data\") # Handle cases where the folder has no valid data \n",
    "        remove_folders(path) # Remove the folder if there's an issue\n",
    "        \n",
    "        pass # Continue without stopping on error \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all folders containing spectral bands\n",
    "\n",
    "\n",
    "flist = []\n",
    "\n",
    "rootdir = os.path.normpath('./SEN12FLOOD')  # Get the absolute path for the root directory\n",
    "#rootdir = './SEN12FLOOD' \n",
    "for file in os.listdir(rootdir):\n",
    "    d = os.path.join(rootdir, file) # Create the full path for each file/folder\n",
    "    if os.path.isdir(d):    # Check if it's a folder\n",
    "        flist.append(d)     # Add folder to the list\n",
    "        \n",
    "# Print the total number of folders found        \n",
    "print(f\"The number of folders are currently = {len(flist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to create the directory structure for the initial folder list (can run up to 1-2 min)\n",
    "create_dir_structure(flist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new list of folders that start with 'S2_'\n",
    "\n",
    "flist = []\n",
    "#rootdir = './SEN12FLOOD'\n",
    "rootdir = os.path.normpath('./SEN12FLOOD')\n",
    "for file in os.listdir(rootdir):\n",
    "     if 'S2_' in file:\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            flist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of folders are currently = {len(flist)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Iterate through all folders and create a new image with 4 spectral bands:\n",
    "# Band2 (blue), Band3 (green), Band4 (red), and Band8 (infrared)\n",
    "#This process can take up to 2-5 minutes to complete\n",
    "\n",
    "\n",
    "for folder_path in flist:\n",
    "    empty = check_empty_img(folder_path) # Check if the folder contains empty images (all pixels are zero)\n",
    "    if empty:\n",
    "        \n",
    "        print(\"The images inside the current folder are empty - zero\")\n",
    "        remove_folders(folder_path) # Remove the folder if images are empty \n",
    "    else:\n",
    "        stack_bands(folder_path) # Stack the spectral bands if images are valid\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>JSON Metadata Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Step 2: Open and load the JSON file\n",
    "with open('./SEN12FLOOD/S2list.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "print( data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for location_id, location_data in data.items():\n",
    "    for location_date, date_data in location_data.items():\n",
    "        if location_date == 'geo' or location_date =='count' or location_date =='folder': continue\n",
    "        folder = os.path.join(rootdir, 'S2_' + location_id + '_' + date_data['date'])\n",
    "        #print (folder, date_data['FLOODING'])\n",
    "        file = os.path.join(folder, 'flooding.txt')\n",
    "        print(file)\n",
    "\n",
    "\n",
    "        if os.path.isdir(folder):\n",
    "            with open(file, 'w') as f:\n",
    "                f.write(f\"{date_data['FLOODING']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Augmentation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import tifffile as tiff  # TIFF fájlok betöltéséhez és kezeléséhez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),  # 15 fokon belüli véletlenszerű forgatás\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images_in_directory(input_dir):\n",
    "    # Fájlok bejárása a megadott mappában\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file == 'stack.tif':  # Csak a 'stack.tif' képekre fókuszálunk\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # TIFF kép betöltése 4 csatornával (HxWxC)\n",
    "                img = tiff.imread(file_path)\n",
    "                \n",
    "                # Kép tensorrá alakítása és átrendezése (CxHxW formátum PyTorch számára)\n",
    "                img_tensor = torch.from_numpy(img).permute(2, 0, 1).float()\n",
    "                \n",
    "                # Augmentáció alkalmazása\n",
    "                img_transformed = train_transform(img_tensor)\n",
    "                \n",
    "                # Kép visszaalakítása (HxWxC formátumba numpy-hoz)\n",
    "                img_transformed = img_transformed.permute(1, 2, 0).numpy().astype(np.uint16)\n",
    "                \n",
    "                # Augmentált kép mentése új névvel: 'astack.tif'\n",
    "                save_path = os.path.join(root, 'astack.tif')\n",
    "                tiff.imwrite(save_path, img_transformed)\n",
    "                \n",
    "                print(f\"Kép augmentálva és mentve: {save_path}\")\n",
    "\n",
    "# Fő futtatás\n",
    "input_directory = './SEN12FLOOD'  # A gyökérmappa, ahol a mappák találhatóak\n",
    "augment_images_in_directory(input_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data loading</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLabel(path):\n",
    "    filepath = os.path.normpath(os.path.join(path, 'flooding.txt'))\n",
    "    with open(filepath, 'r') as file:\n",
    "        data = file.readline().strip()\n",
    "        if(data ==\"False\"):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flist = []\n",
    "rootdir = os.path.normpath('./SEN12FLOOD')\n",
    "for file in os.listdir(rootdir):\n",
    "     if 'S2_' in file:\n",
    "        d = os.path.join(rootdir, file)\n",
    "        if os.path.isdir(d):\n",
    "            flist.append(d)\n",
    "        \n",
    "        \n",
    "print(f\"The number of folders are currently = {len(flist)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filename to load\n",
    "fileName = \"astack.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for folder in flist:\n",
    "        imagePath = os.path.join(folder, fileName)\n",
    "        image = cv2.imread(imagePath)\n",
    "        images.append(image)\n",
    "\n",
    "        label = getLabel(folder)\n",
    "        labels.append(label)\n",
    "\n",
    "    images = np.array(images, dtype = 'float32')\n",
    "    labels = np.array(labels, dtype = 'int32')\n",
    "\n",
    "    return images, labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    images, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Analysis</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(labels, return_counts=True)\n",
    "\n",
    "print(f\"The number of images in the train dataset containing flooded areas is {counts[1]}\\n\")\n",
    "print(f\"While the number of images clean from floods is {counts[0]}\\n\")\n",
    "percentage = round(counts[1] / (counts[0] + counts[1]) * 100, 3)\n",
    "print(f\"That makes the percentage of flooded areas \" + str(percentage) + \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model Definition</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (512, 512, 3)), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit( X_train, y_train, batch_size=28, epochs=20, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Evaluation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy_loss(history):\n",
    "    \"\"\"\n",
    "        Plot the accuracy and the loss during the training of the nn.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "    # Plot accuracy\n",
    "    plt.subplot(221)\n",
    "    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n",
    "    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n",
    "    plt.title(\"train_acc vs val_acc\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot loss function\n",
    "    plt.subplot(222)\n",
    "    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n",
    "    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n",
    "    plt.title(\"train_loss vs val_loss\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
